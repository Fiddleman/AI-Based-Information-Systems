{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI 1 Exercise 2: \"Introduction to Python\"\n",
    "\n",
    "## 2.3 Wine Quality\n",
    "\n",
    "#### a) You import the data and start exploring to gather a better understanding of it by checking, e.g., data types, number of columns and rows, number of missing values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1594</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1595</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1596</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1597</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1598</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import the data\n",
    "wine = pd.read_csv(\"wineQuality.csv\")\n",
    "wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      "fixed acidity           1599 non-null float64\n",
      "volatile acidity        1599 non-null float64\n",
      "citric acid             1599 non-null float64\n",
      "residual sugar          1599 non-null float64\n",
      "chlorides               1599 non-null float64\n",
      "free sulfur dioxide     1599 non-null float64\n",
      "total sulfur dioxide    1599 non-null float64\n",
      "density                 1599 non-null float64\n",
      "pH                      1599 non-null float64\n",
      "sulphates               1599 non-null float64\n",
      "alcohol                 1599 non-null float64\n",
      "quality                 1599 non-null int64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fixed acidity           0\n",
       "volatile acidity        0\n",
       "citric acid             0\n",
       "residual sugar          0\n",
       "chlorides               0\n",
       "free sulfur dioxide     0\n",
       "total sulfur dioxide    0\n",
       "density                 0\n",
       "pH                      0\n",
       "sulphates               0\n",
       "alcohol                 0\n",
       "quality                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get an overview of the data\n",
    "wine.info()\n",
    "wine.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Then, you decide to bin the “quality” column into two categories “mediocre” and “excellent”. However, before you do, you have to get an overview of the quality values and their distribution by visualizing them in a fitting plot. How many data points did you place in each category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    681\n",
      "6    638\n",
      "7    199\n",
      "4     53\n",
      "8     18\n",
      "3     10\n",
      "Name: quality, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a1c3bead0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Getting an overview\n",
    "count=wine[\"quality\"].value_counts()\n",
    "quality=pd.Series(wine[\"quality\"])\n",
    "quality=quality.sort_values(ascending=True)\n",
    "print(count)\n",
    "fig, chart = plt.subplots(2, 2, figsize=(5,5))\n",
    "chart[0,0].hist(quality)\n",
    "chart[1,0].pie(count)\n",
    "chart[1,1].plot(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mediocre, excellent]\n",
       "Categories (2, object): [mediocre < excellent]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the two bins\n",
    "bins=(2,5.9,8)\n",
    "groups=['mediocre','excellent']\n",
    "wine['quality']=pd.cut(wine['quality'],bins=bins,labels=groups)\n",
    "\n",
    "wine['quality'].unique() # just to display the below output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excellent    855\n",
      "mediocre     744\n",
      "Name: quality, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(wine['quality'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Afterwards, you set the “quality” column as the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    855\n",
       "1    744\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.preprocessing as spp\n",
    "\n",
    "LE=spp.LabelEncoder()\n",
    "wine['quality']=LE.fit_transform(wine['quality'])\n",
    "\n",
    "wine['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Then, you decide to scale the data using the scikit-learn function “StandardScaler”. What does it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCALED DATA:\n",
      "[[-0.52835961  0.96187667 -1.39147228 ...  1.28864292 -0.57920652\n",
      "  -0.96024611]\n",
      " [-0.29854743  1.96744245 -1.39147228 ... -0.7199333   0.1289504\n",
      "  -0.58477711]\n",
      " [-0.29854743  1.29706527 -1.18607043 ... -0.33117661 -0.04808883\n",
      "  -0.58477711]\n",
      " ...\n",
      " [-1.1603431  -0.09955388 -0.72391627 ...  0.70550789  0.54204194\n",
      "   0.54162988]\n",
      " [-1.39015528  0.65462046 -0.77526673 ...  1.6773996   0.30598963\n",
      "  -0.20930812]\n",
      " [-1.33270223 -1.21684919  1.02199944 ...  0.51112954  0.01092425\n",
      "   0.54162988]]\n",
      "NON-SCALED DATA:\n",
      "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0               7.4             0.700         0.00             1.9      0.076   \n",
      "1               7.8             0.880         0.00             2.6      0.098   \n",
      "2               7.8             0.760         0.04             2.3      0.092   \n",
      "3              11.2             0.280         0.56             1.9      0.075   \n",
      "4               7.4             0.700         0.00             1.9      0.076   \n",
      "...             ...               ...          ...             ...        ...   \n",
      "1594            6.2             0.600         0.08             2.0      0.090   \n",
      "1595            5.9             0.550         0.10             2.2      0.062   \n",
      "1596            6.3             0.510         0.13             2.3      0.076   \n",
      "1597            5.9             0.645         0.12             2.0      0.075   \n",
      "1598            6.0             0.310         0.47             3.6      0.067   \n",
      "\n",
      "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
      "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
      "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
      "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
      "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
      "...                   ...                   ...      ...   ...        ...   \n",
      "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
      "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
      "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
      "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
      "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
      "\n",
      "      alcohol  quality  \n",
      "0         9.4        1  \n",
      "1         9.8        1  \n",
      "2         9.8        1  \n",
      "3         9.8        0  \n",
      "4         9.4        1  \n",
      "...       ...      ...  \n",
      "1594     10.5        1  \n",
      "1595     11.2        0  \n",
      "1596     11.0        0  \n",
      "1597     10.2        1  \n",
      "1598     11.0        0  \n",
      "\n",
      "[1599 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "wine_pre_scale = wine  # if you want to compare the original data later\n",
    "\n",
    "scaler=spp.StandardScaler()\n",
    "X = wine.drop('quality',axis=1) # Remove target variable which will be handled separately later\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "print(\"SCALED DATA:\")\n",
    "print(X)\n",
    "\n",
    "print(\"NON-SCALED DATA:\")\n",
    "print(wine_pre_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) To finalize your preprocessing, you split the data into a training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "[[ 2.34429261 -0.99339013  1.12470036 ... -1.23827555  0.54204194\n",
      "  -0.02157362]\n",
      " [-0.93053092  1.2412005  -1.34012182 ...  1.54781404 -0.28414114\n",
      "   2.23124036]\n",
      " [-0.98798397  0.57082331 -1.39147228 ... -0.7199333  -1.22835037\n",
      "  -0.86637886]\n",
      " ...\n",
      " [-0.6432657   0.51495855 -1.08336951 ...  1.28864292 -0.69723268\n",
      "  -0.86637886]\n",
      " [-0.24109439 -1.83136161  0.4057939  ...  0.05758008  0.83710732\n",
      "   1.38643512]\n",
      " [-1.44760832 -1.32857872 -0.05636026 ...  0.51112954 -0.69723268\n",
      "   2.8883111 ]]\n",
      "-----\n",
      "X_test:\n",
      "[[-0.35600048  0.17976995 -0.98066858 ... -0.46076217  0.01092425\n",
      "  -0.77251161]\n",
      " [-0.29854743 -0.15541864 -0.51851442 ...  0.51112954 -1.05131114\n",
      "  -0.86637886]\n",
      " [ 1.36759086  0.79428237 -0.26176211 ... -0.20159105  1.89934271\n",
      "  -0.49090986]\n",
      " ...\n",
      " [-0.01128221 -1.21684919  0.61119574 ... -0.0072127   0.66006809\n",
      "   1.94963861]\n",
      " [-0.06873526  4.48135691 -1.39147228 ...  1.41822848 -0.99229806\n",
      "   0.44776263]\n",
      " [ 0.44834214  0.73841761 -0.62121535 ... -0.20159105 -0.69723268\n",
      "  -0.77251161]]\n",
      "-----\n",
      "y_train:\n",
      "548     0\n",
      "355     0\n",
      "1296    1\n",
      "209     0\n",
      "140     1\n",
      "       ..\n",
      "1130    0\n",
      "1294    0\n",
      "860     1\n",
      "1459    0\n",
      "1126    0\n",
      "Name: quality, Length: 1071, dtype: int64\n",
      "-----\n",
      "y_test:\n",
      "803     0\n",
      "124     1\n",
      "350     0\n",
      "682     1\n",
      "1326    0\n",
      "       ..\n",
      "813     1\n",
      "377     0\n",
      "898     0\n",
      "126     1\n",
      "819     1\n",
      "Name: quality, Length: 528, dtype: int64\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection as model_selection\n",
    "\n",
    "y = wine['quality'] # Target variable (was previously removed from X)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y, test_size = 0.33, random_state = 42)\n",
    "\n",
    "print(\"X_train:\")\n",
    "print(X_train)\n",
    "print(\"-----\")\n",
    "\n",
    "print(\"X_test:\")\n",
    "print(X_test)\n",
    "print(\"-----\")\n",
    "\n",
    "print(\"y_train:\")\n",
    "print(y_train)\n",
    "print(\"-----\")\n",
    "\n",
    "print(\"y_test:\")\n",
    "print(y_test)\n",
    "print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f) You decide to train several models using the following algorithms: Decision Tree, Random Forest, Support Vector Machine, Neural Network, and Linear Regression.\n",
    "\n",
    "\n",
    "**NOTE:** You will receive a warning that you neural network has not converged yet. To resolve this, you can increase the number of iterations which will lead to a longer run time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TimoSturm/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train and Apply on Test Data for the differnt algorithms\n",
    "\n",
    "# DECISION TREE\n",
    "from sklearn import tree\n",
    "\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(X_train,y_train)\n",
    "dt_predict = dt.predict(X_test)\n",
    "\n",
    "\n",
    "# RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=150)\n",
    "forest.fit(X_train, y_train)\n",
    "forest_predict = forest.predict(X_test)\n",
    "\n",
    "\n",
    "# SUPPORT VECTOR MACHINE\n",
    "import sklearn.svm as svm\n",
    "\n",
    "sup = svm.SVC(gamma='auto')\n",
    "sup.fit(X_train, y_train)\n",
    "sup_predict=sup.predict(X_test)\n",
    "\n",
    "\n",
    "# NEURAL NETWORK (MLP = Multi-layer Perceptron)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nn = MLPClassifier(hidden_layer_sizes=(15), random_state=1)\n",
    "nn.fit(X_train, y_train)\n",
    "nn_predict = nn.predict(X_test)\n",
    "\n",
    "\n",
    "# LINEAR REGRESSION\n",
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "# X2_test = scaler.transform(X2_test)   EVENTUELL ANWENDEN!!!\n",
    "LR = LinearRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "LR_predict = LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. DECISION TREE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.76       290\n",
      "           1       0.71      0.72      0.72       238\n",
      "\n",
      "    accuracy                           0.74       528\n",
      "   macro avg       0.74      0.74      0.74       528\n",
      "weighted avg       0.74      0.74      0.74       528\n",
      "\n",
      "[[221  69]\n",
      " [ 67 171]]\n",
      "\n",
      "\n",
      "Detailed Accuracy:\n",
      "0.7424242424242424\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "\n",
      "2. RANDOM FOREST:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       290\n",
      "           1       0.78      0.76      0.77       238\n",
      "\n",
      "    accuracy                           0.80       528\n",
      "   macro avg       0.80      0.80      0.80       528\n",
      "weighted avg       0.80      0.80      0.80       528\n",
      "\n",
      "[[240  50]\n",
      " [ 56 182]]\n",
      "\n",
      "\n",
      "Detailed Accuracy:\n",
      "0.7992424242424242\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "\n",
      "3. SUPPORT VECTOR MACHINE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78       290\n",
      "           1       0.72      0.77      0.75       238\n",
      "\n",
      "    accuracy                           0.76       528\n",
      "   macro avg       0.76      0.76      0.76       528\n",
      "weighted avg       0.77      0.76      0.76       528\n",
      "\n",
      "[[220  70]\n",
      " [ 55 183]]\n",
      "\n",
      "\n",
      "Detailed Accuracy:\n",
      "0.7632575757575758\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "\n",
      "4. NEURAL NETWORK:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       290\n",
      "           1       0.69      0.74      0.72       238\n",
      "\n",
      "    accuracy                           0.73       528\n",
      "   macro avg       0.73      0.74      0.73       528\n",
      "weighted avg       0.74      0.73      0.74       528\n",
      "\n",
      "[[212  78]\n",
      " [ 62 176]]\n",
      "\n",
      "\n",
      "Detailed Accuracy:\n",
      "0.7348484848484849\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "\n",
      "5. LINEAR REGRESSION:\n",
      "Root Mean Squared Error (RMSE):\n",
      "0.425360802083977\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Performance of the different Models\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# DECISION TREE\n",
    "print(\"1. DECISION TREE:\")\n",
    "print(classification_report(y_test, dt_predict))\n",
    "print(confusion_matrix(y_test, dt_predict))\n",
    "print(\"\\n\")\n",
    "print(\"Detailed Accuracy:\")\n",
    "print(accuracy_score(y_test, dt_predict))\n",
    "print(\"\\n\")\n",
    "print(\"----------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# RANDOM FOREST\n",
    "print(\"2. RANDOM FOREST:\")\n",
    "print(classification_report(y_test, forest_predict))\n",
    "print(confusion_matrix(y_test, forest_predict))\n",
    "print(\"\\n\")\n",
    "print(\"Detailed Accuracy:\")\n",
    "print(accuracy_score(y_test, forest_predict))\n",
    "print(\"\\n\")\n",
    "print(\"----------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# SUPPORT VECTOR MACHINE\n",
    "print(\"3. SUPPORT VECTOR MACHINE:\")\n",
    "print(classification_report(y_test, sup_predict))\n",
    "print(confusion_matrix(y_test, sup_predict))\n",
    "print(\"\\n\")\n",
    "print(\"Detailed Accuracy:\")\n",
    "print(accuracy_score(y_test, sup_predict))\n",
    "print(\"\\n\")\n",
    "print(\"----------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# NEURAL NETWORK\n",
    "print(\"4. NEURAL NETWORK:\")\n",
    "print(classification_report(y_test, nn_predict))\n",
    "print(confusion_matrix(y_test, nn_predict))\n",
    "print(\"\\n\")\n",
    "print(\"Detailed Accuracy:\")\n",
    "print(accuracy_score(y_test, nn_predict))\n",
    "print(\"\\n\")\n",
    "print(\"----------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# SPECIAL CASE: Linear Regression performs a regression and not a classification. \n",
    "# Thus, we have to apply other evaluation metrics, such as, e.g., root mean squared error.\n",
    "\n",
    "# LINEAR REGRESSION\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "from math import sqrt\n",
    "\n",
    "print(\"5. LINEAR REGRESSION:\")\n",
    "print(\"Root Mean Squared Error (RMSE):\")\n",
    "print(sqrt(mean_squared_error(y_test, LR_predict)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
